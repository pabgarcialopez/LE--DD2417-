{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "478c3b76-d2ed-4b70-8acd-4e40a15ba6a9",
   "metadata": {},
   "source": [
    "# Assignment 4, task 3\n",
    "\n",
    "In this task, you are going to implement a character model based on the Transformer architecture, starting from the provided skeleton. It is useful to first do exercise 2 before starting on this task.\n",
    "\n",
    "The model you are going to implement here will have a context of 32 characters, i.e. it will consider the preceding 32 characters when estimating the probabilities of the possible character coming next. Due to the clever transformer architecture, the model will have less than 50,000 trainable parameters. As a comparison, the simpler model in exercise 2 only had a context of 8 characters but had more than 300,000 trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ab7eca6-a6b5-4325-be4c-4e0f0ad09e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First run this cell\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbde199-fa08-4c83-b496-52c5b69df042",
   "metadata": {},
   "source": [
    "We need to map every type of input item (every character, in our case) to a unique ID number. Since we are not sure which characters will appear in our training text, we are going to create new IDs as we encounter new kinds of characters we haven't seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9510ea6e-4171-41e5-94c7-621d6424042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_id = {}  # Dictionary to store character-to-ID mapping\n",
    "id_to_char = []  # List to store characters in their ID ordering\n",
    "PADDING_SYMBOL = '<PAD>'\n",
    "char_to_id[PADDING_SYMBOL] = 0\n",
    "id_to_char.append(PADDING_SYMBOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb6f3e4-1702-4739-916c-d2e005493697",
   "metadata": {},
   "source": [
    "We now define a class 'CharDataset' that extends the predefined 'Dataset' class. Compared to exercise 2, we will create data points in a slightly different way. \n",
    "\n",
    "The init function reads a training text and splits it up into chunks $n$ characters long. From each chunk, $n$ data points with a corresponding label will be created, as in the following example:\n",
    "\n",
    "Suppose $n=8$. From a chunk $[4,5,9,11,7,7,2,12]$ with 14 being the next character ID, the following data points and labels will be formed (0 is the padding symbol):\n",
    "\n",
    "| Data point | Label |\n",
    "|-----------:|------:|\n",
    "|[4,0,0,0,0,0,0,0] | 5 |\n",
    "|[4,5,0,0,0,0,0,0] | 9 |\n",
    "|[4,5,9,0,0,0,0,0] | 11 |\n",
    "|[4,5,9,11,0,0,0,0] | 7 |\n",
    "|[4,5,9,11,7,0,0,0] | 7 |\n",
    "|[4,5,9,11,7,7,0,0] | 2 |\n",
    "|[4,5,9,11,7,7,2,0] | 12 |\n",
    "|[4,5,9,11,7,7,2,12] | 14 |\n",
    "\n",
    "This way, the model will learn to infer the next character even if the context is shorter than $n$. This is a very useful feature, particularly in 'real' language models, where the known context often is shorter than the maximal context length.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "484e5020-20e4-4c9f-8bf1-c97feeae0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "\n",
    "    def __init__(self, file_path, n):\n",
    "        self.datapoints = []\n",
    "        self.labels = []\n",
    "        chars = []\n",
    "        try:\n",
    "            # First read the dataset to find all the unique characters\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                contents = f.read()\n",
    "            # YOUR CODE HERE\n",
    "            for char in contents:\n",
    "                if char not in char_to_id:\n",
    "                    char_to_id[char] = len(id_to_char)\n",
    "                    id_to_char.append(char)\n",
    "                chars.append(char_to_id[char])\n",
    "            # Then go through all the chars and chunk them up into datapoints\n",
    "            k = 0\n",
    "            while k < len(chars) - n:\n",
    "                for i in range(1, n + 1):\n",
    "                    self.datapoints.append([c for c in chars[k : i + k] + [0] * (n - i)])\n",
    "                    self.labels.append(chars[i + k])\n",
    "                k += n\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datapoints)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx % len(self.datapoints)\n",
    "        return torch.tensor(self.datapoints[idx]), torch.tensor(self.labels[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e657a49b-9609-483a-a205-9533e933de4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Verify\n",
    "dataset = CharDataset('HP_book_1.txt', 32) # Max context is 32 characters long.\n",
    "d63,l63 = dataset[63]\n",
    "d1048575,l1048575 = dataset[1048575]\n",
    "d1048576,l1048576 = dataset[1048576]\n",
    "print(d63[16].item() == l63.item())\n",
    "print(d63[4].item() == l1048575.item())\n",
    "print(sum(d1048576[1:]).item() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb3c12c-bc54-45ce-b5f6-cf91816499f8",
   "metadata": {},
   "source": [
    "The __self-attention__ computation is at the core of the Transformer architecture. It is important to get this computation efficient (i.e. vectorized), since it involves many matrix operations that would be very slow if implemented by Python loops.\n",
    "\n",
    "The input to the self-attention computation is a tensor containing a vector for each input token, and the output is a tensor of the same dimensions, containing the contextualized versions of the input tokens (see Lecture 9 and the textbook, chapters 10.1 and 10.2).\n",
    "\n",
    "Your task is to fill in the missing pieces below. Look for \"REPLACE WITH YOUR CODE\" and \"YOUR CODE HERE\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea2dea08-54af-4ee5-b8b6-a945687dfc08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculates self-attention according to [Vaswani et al., NeurIPS, 2017]\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, number_of_attention_heads):\n",
    "        super().__init__()\n",
    "        # The number of attention heads cannot be more than the hidden size\n",
    "        assert hidden_size > number_of_attention_heads\n",
    "\n",
    "        self.number_of_attention_heads = number_of_attention_heads\n",
    "        # Divide the hidden_size roughly equal over the different heads\n",
    "        self.attention_head_size = int(hidden_size / number_of_attention_heads)\n",
    "        self.all_head_size = number_of_attention_heads * self.attention_head_size\n",
    "\n",
    "        # Mapping from input to the query, key, and, value vectors\n",
    "        self.query = nn.Linear(hidden_size, self.all_head_size, bias=False)\n",
    "        self.key = nn.Linear(hidden_size, self.all_head_size, bias=False)\n",
    "        self.value = nn.Linear(hidden_size, self.all_head_size, bias=False)\n",
    "\n",
    "        self.final = nn.Linear(self.all_head_size, hidden_size, bias=False)\n",
    "\n",
    "    def reshape_for_multihead_attention(self, x):\n",
    "        # x has the shape (batch_size, seq_length, hidden_size) = (N, L, H)\n",
    "        N, L, _ = x.shape\n",
    "\n",
    "        # but we want to split the representation of each token into 'number_of_heads' parts:\n",
    "        x = x.reshape(N, L, self.number_of_attention_heads, self.attention_head_size)\n",
    "\n",
    "        # and treat each part separately. Thus, we need the final tensor to have shape\n",
    "        # (batch_size, number_of_heads, seq_length, attention_head_size) = (N, R, L, AHS)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        # All of the tensors below will have the shape\n",
    "        # (N, L, H) = (batch_size, seq_length, hidden_size)\n",
    "        query_all_heads = self.query(hidden_states)\n",
    "        key_all_heads = self.key(hidden_states)\n",
    "        value_all_heads = self.value(hidden_states)\n",
    "\n",
    "        # All of the tensors below will have the shape\n",
    "        # (N, R, L, AHS) = (batch_size, number_of_heads, seq_length, attention_head_size)\n",
    "        Q = self.reshape_for_multihead_attention(query_all_heads)\n",
    "        K = self.reshape_for_multihead_attention(key_all_heads)\n",
    "        V = self.reshape_for_multihead_attention(value_all_heads)\n",
    "\n",
    "        # attention_scores will have the shape\n",
    "        # (N, R, L, L) = (batch_size, number_of_heads, seq_length, seq_length)\n",
    "        # (N, R, L, AHS) x (N, R, AHS, L) --> (N, R, L, L)\n",
    "        attention_scores = Q.matmul(K.transpose(2, 3))\n",
    "\n",
    "        # Scale to reduce variance. Divide by d_k = Q.shape[3]\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "\n",
    "        # Use softmax to turn the attention scores into probabilities.\n",
    "        # We want zero scores to be zero probabilities -- hence we turn\n",
    "        # zero scores into -infinity before the softmax exponentiation.\n",
    "        # Create a mask for the upper triangular part\n",
    "        mask = torch.triu(torch.ones_like(attention_scores), diagonal=1)\n",
    "        # Update the tensor using the mask\n",
    "        attention_scores = attention_scores.masked_fill(mask == 1, float('-inf'))\n",
    "        attention_scores = attention_scores.softmax(3)  # 3 so that rows sum up to 1.\n",
    "\n",
    "        # Now produce the contextualized vectors for each head\n",
    "        # The tensor below will have shape\n",
    "        # (N, R, L, AHS) = (batch_size, number_of_heads, seq_length, attention_head_size)\n",
    "        # (N, R, L, L) x (N, R, L, AHS) --> (N, R, L, AHS)\n",
    "        self_attention_all_heads_separately = attention_scores.matmul(V)\n",
    "\n",
    "        # For each token, we now want to bring together the representation coming from each head.\n",
    "        # The 'self_attention' tensor below should have the shape\n",
    "        # (N, L, R * AHS) = (batch size, seq_length_, self.all_heads_size)\n",
    "        N, R, L, AHS = self_attention_all_heads_separately.shape\n",
    "        self_attention = self_attention_all_heads_separately.transpose(1, 2).reshape(N, L, R * AHS)\n",
    "\n",
    "        # Finally, make sure that the output has the correct dimensions\n",
    "        # (N, L, H) = (batch_size,seq_length,hidden_size)\n",
    "        # final(N, L, R * AHS) --> (N, L, H)\n",
    "        return self.final(self_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42feb356-82ee-4370-99de-23dc153ddc62",
   "metadata": {},
   "source": [
    "After the self-attention computation, the Transformer encoder block contains layer-normalization computations and a feed-forward layer. The code is given below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf90f50c-8485-4e83-a7b4-670c643b5815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFFN(nn.Module):\n",
    "    \"\"\"\n",
    "    The position-wise FFN that follows after the self-attention\n",
    "    computation.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, dropout_prob):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        for module in (self.fc1, self.fc2):\n",
    "            nn.init.kaiming_normal_(module.weight)\n",
    "            nn.init.constant_(module.bias, 0.)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.dropout(torch.relu(self.fc1(x))))\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer encoder block.\n",
    "\n",
    "    This version differs from the original version in  [Vaswani et al. NeurIPS 2017],\n",
    "    and applies the LayerNorm before the self-attention, and before the FFN, as this\n",
    "    has proved to be beneficial (see [Nguyen and Salazar 2019]).\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, number_of_attention_heads, dropout_prob):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadSelfAttention(hidden_size, number_of_attention_heads)\n",
    "        self.ffn = PositionwiseFFN(hidden_size, dropout_prob)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.ln1 = nn.LayerNorm(hidden_size)\n",
    "        self.ln2 = nn.LayerNorm(hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.ln1(x)\n",
    "        x2 = x + self.dropout(self.attn(x1))\n",
    "        x3 = self.ln2(x2)\n",
    "        x4 = x2 + self.dropout(self.ffn(x3))\n",
    "        return x4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edefcae-564e-4a79-8724-42f7f218f4e7",
   "metadata": {},
   "source": [
    "Here is the actual character-based language model, which uses the Transformer implementation above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c540c7d3-04e8-4ccd-907c-75b7b3d999e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= Hyper-parameters for training ============== #\n",
    "\n",
    "class Config:\n",
    "    number_of_transformer_encoders = 1\n",
    "    number_of_attention_heads = 1\n",
    "    hidden_size = 64\n",
    "    dropout_prob = 0.1\n",
    "    batch_size = 64\n",
    "    learning_rate = 0.0003\n",
    "    weight_decay = 0.000001\n",
    "    no_of_epochs = 100\n",
    "\n",
    "MAXLEN = 32   # This is the number of characters we will consider when \n",
    "              # predicting the next character\n",
    "\n",
    "# ======================= The model ======================= #\n",
    "\n",
    "class CharLM(nn.Module):\n",
    "\n",
    "    def __init__(self, config, no_of_input_chars):\n",
    "        super(CharLM, self).__init__()\n",
    "        self.config = config\n",
    "        self.embed = nn.Embedding(no_of_input_chars, config.hidden_size)\n",
    "        # Make sure that the padding symbol (which has ID 0) is embedded\n",
    "        # as a vector of 0s.\n",
    "        self.embed.weight.data[0].fill_(0)\n",
    "        self.positional = nn.Parameter(torch.randn(1, MAXLEN, config.hidden_size))\n",
    "        modules = [EncoderBlock(config.hidden_size,\n",
    "                                config.number_of_attention_heads,\n",
    "                                config.dropout_prob) for _ in range(config.number_of_transformer_encoders)]\n",
    "        self.transformers = nn.ModuleList(modules)\n",
    "        self.final = nn.Linear(config.hidden_size*MAXLEN, no_of_input_chars)\n",
    "\n",
    "    def forward(self, x):\n",
    "        number_of_datapoints = x.shape[0]\n",
    "        # First create a mask distinguishing 0 from positive word IDs\n",
    "        non_zero_mask = (x != 0)\n",
    "        word_embeddings = self.embed(x)\n",
    "        # Add positional vectors in all non-padded positions\n",
    "        pos = self.positional.expand_as(word_embeddings)\n",
    "        pos = pos * non_zero_mask.unsqueeze(-1).float()\n",
    "        t = word_embeddings + pos\n",
    "        # Then apply the transformers and make a final prediction at the end\n",
    "        for transf in self.transformers:\n",
    "            t = transf(t)\n",
    "        flattened_transf = t.reshape(number_of_datapoints, 1, -1)\n",
    "        result = self.final(torch.tanh(flattened_transf))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ffe7817d-f56f-465c-8499-aacc4298889b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n",
      "There are 442720 datapoints and 81 unique characters in the dataset\n",
      "14:28:51 Training starts\n",
      "14:29:07 End of epoch 1 , loss= 2.484036922454834\n",
      " an ann ano and  oon uth athe rin atn inen ton aen ton  ooun tn toon  taore  toon  toan e toan  tonn e aoarn  tan y aoarn tto on  aonn dno Hon ton te nar aer ayry yos aan atr  oond  aand  aarnyr yaand  aand  toon en aand  oand y aoonn  aanr  otone  aand  tono en aand  oarryy aan end aor yos so nan a\n",
      "14:29:23 End of epoch 2 , loss= 2.4872732162475586\n",
      " an enand  oond  tooun t hoo tus thee ran tee trree canre seer arrey and asr arley asd and and aon ton ton the ere toe ton the the ene tar eer anre nge too tou the the the e anr and anree tor theer enr oor sound end and aar yon ton the e and aar sand angre tee the and ang inge ton ton ton tho the th\n",
      "14:29:38 End of epoch 3 , loss= 2.3104183673858643\n",
      " and an eardy  \n",
      "Iound e and the the the ere and ond and anre yto and ard ary arind and and are tan ton the ere toe ton ton the the ene and and onre tou the tra the the ere and and and anre yto and ard ary arind and and are tan ton the ere toe ton ton the the ene and and onre tou the tra the the ere \n",
      "14:29:54 End of epoch 4 , loss= 2.217421293258667\n",
      " and an int hee pere toun the the the ere aren do the the anrd yaar sy aard ysa and and waled Har yas thind eng ate tro and ang ott hoe tar son tar sot home ere the ars and asre tas ard yas was aind  \n",
      "astin gounn the the to has to the are was ass theed and and and and Hot herere yto une the and the \n",
      "14:30:09 End of epoch 5 , loss= 2.3585846424102783\n",
      " Harryy asr and and and Horery and ary anlyy waing the and at heren don won tou the the the and ong out here ywa tras san don ton tore tou the the and are tron gon too the the the and and ong out here yru the alrye sat the and and and and on too the the the and ang ont on tou there yranl yit whee to\n",
      "14:30:25 End of epoch 6 , loss= 2.1879165172576904\n",
      " Harryy as and yaw inge the sas tas win gont hoang whainn gout hing and ong arte toh ton wout hon tou the the the arrey and and and oon tou the the the ere was tar yon tore saud wan das ton the the ere and here ywan rery anl onge toh tou the the wan ton tore tre ary was iss and ang oto tuh tor ang t\n",
      "14:30:40 End of epoch 7 , loss= 2.3040242195129395\n",
      " Harryy as and ang out hen toon the arry sout Hine groring to the the and ang orte hee ton the srout she and and arrye sas bad and and and and ont out here yfu the the the the arrey and and and oon tou the the the ere was pas tor ange teh and arry you the and and art oun ton the the erex ton the toe\n",
      "14:30:56 End of epoch 8 , loss= 2.254934549331665\n",
      " Harryy aso wne toon the the woing the anr oto wuhnge toh as the pound wase tou the the wan tor and ang out hon ter thee ter and arre yound theex the per atre sasd and arrye sat whee se tho and and ong out here tou the the the arrey sound and ong out the and athe sard and ang oon tout her arry saing\n",
      "14:31:11 End of epoch 9 , loss= 2.2729668617248535\n",
      " Harryy far yon and and ato sto hee ter and and ong out hon too the the the par sof fored sat: won tou the and at hared sand yon wout hon te the and ong out the anr atre soud the pan ton tared sof arrey sout Herry and arrey was asd and and and onw aton the the was the arry sat son Mougne the and as \n",
      "14:31:27 End of epoch 10 , loss= 2.1681969165802\n",
      " Her one toon tou the the was tas the pee farringe soud Horry fat sout the sarde fary fainn the ard orand yne wounge toh and arre yfa lnod you the wan tan the arry sout sone won the arrya sand yin gone toun the the ton atre sout the aring the pis ton fared sof arry bound --- found at the and ary and\n",
      "14:31:42 End of epoch 11 , loss= 2.0271852016448975\n",
      " Her one tow and arde the the the the Vre fared sared sared sat won asre the and and ars ary ing oond wot here the the and oron ton arrey sand yin ton atre the and ong out the anr too farry and and oow and to unt here yfe anr youn ton at lerey the and and ars toon ton tohe the ared sat and arrey won\n",
      "14:31:58 End of epoch 12 , loss= 2.098982334136963\n",
      " in thee sray con; and and ary aring the found ent out here the sourd and ong at lore yth eand to har sore ton at sorre ton ang ot hou pere satd and too the the was tan dor qounge poully the and to her arrey was won too fan tor uthe grout shere yna too fra ton the the far sored lof and and out here \n",
      "14:32:14 End of epoch 13 , loss= 2.093066453933716\n",
      " Her and offery int he yas ton as the freer and ofr ass too found and ars otw hand you caud and the the the fary and on too fer atse carrye sat inge tow asne the and ong ary too unl at eusre tas the the fary ofur sof fared sat porem sote sred and on too far at the y and off arrey won the and at yon \n",
      "14:32:29 End of epoch 14 , loss= 2.051710605621338\n",
      " see sinde canry woon and arse ton at do mould ing art ofun ton at the and and ast arrey ton wout he maind the ared fanry soand win won ound and ary won atn hee tor utg hared sat atd hem abree to sut had ing ally yfo und athe yne Von wous there y woan soud Herry yfo furey fofruy tas and as the ared \n",
      "14:32:45 End of epoch 15 , loss= 2.084625720977783\n",
      " seeve reer yfe fary ofun tol to the are froon sarde sat wone the and ast and aring yle wous the and to uth egre far yon fore the are sot was bad atr and ang oon tor uthe the and ars ofon ton are toh uthe sar atl ars ofan don wo the and and ong out here tou the freer sary ton -on and oon wous te har\n",
      "14:33:01 End of epoch 16 , loss= 1.908988118171692\n",
      " seeve neer yfe inly ofured lof fore the the and and arse calyly and ong out here the the and too fron athe per ass arse cand ong arond and out heme and of ufre toon the y heme and of rourne too fut the pas tow faring the ary Buond the and ary wous thee pere the farry fon: the as wand and ary and on\n",
      "14:33:17 End of epoch 17 , loss= 2.0501291751861572\n",
      " seeve neer yfe inly ofured lof fore the the ass atre mone and ary and out hand yfo wous the and the as lorem abree dourt end arse the and ong ared to the the farry foing the ars ate was the and arre soud Harry fas forem and ast Hore rom anre yxo won'g the the the as pas tor fourd and ary ofu the so\n",
      "14:33:33 End of epoch 18 , loss= 2.092017412185669\n",
      " said ned at linge to the ars ofurry feer yse woand -o to was the anr yound ong at tor tou fary the the ars ass tow and onge the and to uth asre ywo ans arse casre das Mon tof forem jMally fooun the ars ary and ont and arrey wes as the ared loon the and tou the sary toon the an das tor for foreme th\n",
      "14:33:50 End of epoch 19 , loss= 2.0490055084228516\n",
      " seve erery ans ofre yon wout the ars at the fary ofr anre yfe and ofu fron tan doon the arry soond -- Moung the the and ald orfe rougnt the fir ton the and at loonk of tour ton the as pote cas tor for forem Mof off are wMon and Bound onge the rome bourne the and the arry and and arse roudt he yfe a\n",
      "14:34:06 End of epoch 20 , loss= 2.01601505279541\n",
      " seeve neer yfe yfor uthe the and as atd oron tar sort wounge tor and the for and Bound yhe and oun toh arry sound eray pos, the and as tar boreme the and as to woing the and ont as there samed sot wheer and ound and of the fary and ont arse tou the the sary and arse tou sted an tas the ars ofre mer\n",
      "14:34:22 End of epoch 21 , loss= 1.9511795043945312\n",
      " seen cares fary ofn aring to toh the ars ats aren goound the and ong to the pere to sasre cas ton wares ton and ally you the arme toond erar soned fere yso and of ufre sowe trany the don tou the fary and orfe rougtt her and as to was the and ang to loonk out the ars att heme some wand Bould ing at \n",
      "14:34:38 End of epoch 22 , loss= 1.9528239965438843\n",
      " seeve neer yfe yfer ofle woully the and ars arse coully hey and oru the the farevere ylo wous the and ally yfo and aro wron at the the and as apde doon wout hes arree farry sof forem and out he farry soand wer and ang too ung to tuh pere farry and of toh the arse tof fore the ars arse don toug the \n",
      "14:34:54 End of epoch 23 , loss= 1.811769723892212\n",
      " seeve neer yfe yfe woolung the firry the anr asd and ont and tow ast heme the the froer sfiren tas Moclyo ufre das was the minge toh afre doonug the the far sas tor foond the ars ary and ont as perree the and Bout the and ally yfe and ofu the the finge the romer yof fore the and --- foon the the Ma\n",
      "14:35:10 End of epoch 24 , loss= 1.9774810075759888\n",
      " and and ort out here yfa ting to the the ars ast wone and ars oft here sfeery the and out the the and as tor fout here yfa tre ass tound and ast at here samed yon wone the ary and and and arte ste the the the the the Vreed: froours and the yQu arrey fourse the ars toe frey as tor foound and ar tor \n",
      "14:35:26 End of epoch 25 , loss= 1.919124960899353\n",
      " said Hanry ywa srey the and as utt heer ywas ley fourse the farryy ting the and as tor uthe gon tor for fore the and ar; to sarkey the and ar yof urse jally sound ont as and toj utce saard yot whe mer atn as the ast and ary and ont and and othe the the the was the the and as to was the and you sted\n",
      "14:35:42 End of epoch 26 , loss= 2.010699510574341\n",
      " seen cavere y \n",
      "oully the wing at the and orfe the the fary yfo woor and and of uthe doand the arne the sfired to cuarse lyo ut has ting he tar sorme foorung the the ars ast ing of the and out he farry saed fours end arrey foarn too und at he saind on tou pered  \n",
      "\n",
      "PIem ande srere ylo fuard Gon wout \n",
      "14:35:57 End of epoch 27 , loss= 1.9628565311431885\n",
      " seeve reer and ont and the ant as at loy fourde the ars Vered ne ats, ast Horem ald ary found Ron and ary ats heme wares there samed and Herem inge lroy ust and to and ast heur and ars atte could yhe ans ary and ont as at roumpeed and ant arte ste at loy uthe the was tar bary toh qeur as tow as the\n",
      "14:36:13 End of epoch 28 , loss= 1.9082475900650024\n",
      " seeve reer yfe yfon tout Herry qainge tin jos tor Mome farry Gofne the wor saond ena do quinge lat her as tar yon the moe forre sfit Mon tou chere yfe and as and ort Is the meind ong to harke ton as the and you the the farry yfa lulded  \n",
      "\n",
      "Bout thee star cory ufle Vound yware ylo woand the for tou t\n",
      "14:36:29 End of epoch 29 , loss= 1.8501701354980469\n",
      " Harry fisen goound and at the pas qourte farriy son tou sher as the and Boound at Mhe fore yfa froruse fr;in gon at sor the and as to puinge to for the finghe the forre said Monge farry soon wes ald Mong of fored -- Mof fourg int Mog the the arry and ally of tow the fary one the and ars ary off asr\n",
      "14:36:45 End of epoch 30 , loss= 1.9764797687530518\n",
      " see for at hary the farrey sone was sotre mea could and at the and ars ary foonut Mhere fley as to has firre Dryem ande lounde he mas tor ughe the for uthe ras -os and or the fary ofr off at Mhere yfa ins and orB offe; the \n",
      "Marrey fours, jas to Furid nas some the ars ary foon the ars qooufre sas uM\n",
      "14:37:00 End of epoch 31 , loss= 1.8142770528793335\n",
      " seve mee toh ere vereme stineg to the the as loong to and the ars qooung ind and out Harry Magly, al loNous Herry and arry Masned and Poonde saind  Mand ang at Mogly Mof ully tohung the and orwe saad the yfe luot where sto was the the ars ast ing of theed  \n",
      "\n",
      "\"Ie stopour saly warry fingo the and to \n",
      "14:37:16 End of epoch 32 , loss= 1.8586632013320923\n",
      " seeve reer and young the the the far fore croumes darry; the and --- \n",
      "\n",
      "Herery boung the and ont as qourte pan toh fared sofu the as pares to wass at hore sfared Gnote the ars arse don wof farry ono got whe the the sary Boud the as pally sofre mas tow the farery was whee sarde sand of fored of the a\n",
      "14:37:31 End of epoch 33 , loss= 1.8674652576446533\n",
      " seeve reer yfe loon the the was Mas forry off ofre soutd hary sot; Her arrye sary was; the ward int as qared it the ass ofre yfo uMhling of forer; the as ibde coullly jous ted an the and arse dext wheer fores the and oon the far boren the and -ow and the pares jtous ed af rones to and Bout Mhe ally\n",
      "14:37:47 End of epoch 34 , loss= 1.918885350227356\n",
      " seeve reer yfe toon the the was tow and ars and ing too fres to was the and -go the the as to pounte sar ing to the the as tor fimed not her arse cours fearry the feremy Poonut serer Sone tas ast McGerry foound and Gonre ter and the the and oup pally sound itt hee the anr yes and out hes arry ife f\n",
      "14:38:02 End of epoch 35 , loss= 1.888054609298706\n",
      " seeve reer yfing the for utl as loonk -on wone the ars ary foonud te arny to has its hered wear some Preringe sours wase the and Magring to luond goount hary the ars and ong too for toh fere caus and ars toher me and ars oft ort hes at Mogle farry jous sot woushe the and as tor foreme the ywa luse \n",
      "14:38:18 End of epoch 36 , loss= 1.7928919792175293\n",
      " Harry fisen gere the the the saed all off irte caullly soon the and ars ars arsed --fe the an the as the as pared sofre saming the the and as tor Mome lloougg her as thing to hard and oun got wor the the soumte hing the the and -- hame the and as tor foreme the yre fas tor fing toMrer yfo, far asj \n",
      "14:38:35 End of epoch 37 , loss= 1.7568329572677612\n",
      " and and tow and ter yof quinge the ars too for Bout Mghe for ars ass toonke the he as and as toMreg tary of fourry Masn oned  PNoon eresare jras sound Mogle, the at whe sarding to the the pares ast of the pear sor wast and --g at the and to has ing he the was ass acnid neg at tohe saing the for Mag\n",
      "14:38:50 End of epoch 38 , loss= 2.033799648284912\n",
      " and and Herery soung the the the the raske ward yon tould Magre fally loougl yth as the paing the and ont as tor fours ethe rem Mofrury yfo fore the and -o ufne tha jses as tor uthe pary and all yof tow the fary ont and ith and tow at sheme the was qineg ofre Mrase ywall yof jus tos utc hase the me\n",
      "14:39:06 End of epoch 39 , loss= 1.8654956817626953\n",
      " and and the the the saed Herrye firne gound the and and the the the saed Herrye firne gound the and and the the the saed Herrye firne gound the and and the the the saed Herrye firne gound the and and the the the saed Herrye firne gound the and and the the the saed Herrye firne gound the and and the\n",
      "14:39:22 End of epoch 40 , loss= 1.8714065551757812\n",
      " seeve reer saing the and ont as and -ot whee sree cas to hag itthe  Harry saadn tom at sor the ared and to hars erand yin tohe sto was the and and Gofre the jas pas to ufred and Son att hee to mear sof qoulfied roung the the the ars off fore Mred and as Macny too und ang ard off fore Mfarry,  If at\n",
      "14:39:38 End of epoch 41 , loss= 1.8360695838928223\n",
      " Harry fisen gooturs ing too farle sting he the and Harry of forrey foound as Marred and Gof fored ware yfa luld Voung here freind as parly --o fon the was the and and the dere wast and you gthe the the ars off fore Mromery and --M Goflerrey jas sonded  \n",
      "\n",
      "Tould alte the the the farry ywa lloonde sar\n",
      "14:39:54 End of epoch 42 , loss= 1.9156204462051392\n",
      " Harry fisen, and ont as pirse jtarse the some the ars and ong too freme the as tor fours ethe rye was Soned on tan qout as fared of the Love anr you the saad to farly soound and Heremy at wars and to hee danre sto peald ont hoer was qouut Mhal lyle Vof wourne goorurt ing to the sary woand the ars t\n",
      "14:40:10 End of epoch 43 , loss= 1.967795491218567\n",
      " Harry fay lowe lutd ont hee was and to harke sting the whee sarde samed ont and Heremy ally sours inte coumde tar and the the as thee dar poing the and ont as at Mogre fared at the as was ing he the Bally sound dooung the the the as at loound the as tor fours and ont of the the as and Proemres, wIe\n",
      "14:40:26 End of epoch 44 , loss= 1.9233589172363281\n",
      " Harry foer yse and ont and the as the as pared onf at et hasre saind ing at loong to hasd of the and of Pfoer sof forrey, as saind Magre. PRoen asser Mosg hary. G\n",
      "onMcem allyo found it hary of u-M and and and --- I wally woem as the the pares fary ofn; end as toind on tar sorme the and of Poren jas\n",
      "14:40:41 End of epoch 45 , loss= 1.8372808694839478\n",
      " Harry fisen, and ont heard yqaul yal would yhe fist an firge the and of Proem;e to IMs and Unge Mforuy lobull ang jould ithe sher as the peed an tolly of the ars at efre yof forrey woarn tes and orte far; yhe was the and ast and ing too free the the the sar Magly at lowen do the the ras toh fered a\n",
      "14:40:57 End of epoch 46 , loss= 1.958709716796875\n",
      " Harryy farry, the as the was qainge tas and or the ars ofne soud the paing to toh tos at hare the and yHarrye was ass wqeeree said nog tof the at hears young the and ont as itt heer ywo ans ars off fore the the ars ast and ont and ofr off ast acte sthe Vreme \n",
      "Proonres onde Grerery ans asd ono tMhe \n",
      "14:41:13 End of epoch 47 , loss= 1.8349497318267822\n",
      " and and tof the the et has tis foned of Porevere souns inte carryo wand sout Modle fay tou pand ing too the and as to was the at sherem efarry soonne said Herry was ass at thee the and Bout cher as some the and ofr you the as the and Boutthe reav sere soud Heremrey. \n",
      "\n",
      "\"The ywMe'l las ound goor the \n",
      "14:41:30 End of epoch 48 , loss= 1.9363256692886353\n",
      " fore sande ythe fered of there the ras qainge sared itt hous the ars ally to wask ing too the sal but the yound and ar tound and you the the as tis Pereme the rroonse and Magre fas and ot qouuted ling tohe the the ars as tome the the sared and of qaurey the saud Herry -os tere anzed the saind as th\n",
      "14:41:46 End of epoch 49 , loss= 1.8528786897659302\n",
      " Harryy farry inge was toh tan dounge the and tou the roust and you: the tVe could and of the srougthe roud bally ing to athe dount I the sared and you: not whee saud Harry foound and yound and the the ywa ster and of the pearde sto and to uthe das tor fing tow the the rany was sof too not Magre fou\n",
      "14:42:02 End of epoch 50 , loss= 1.8201904296875\n",
      " Harryy fore the and ithe was tohe was the and Sone the saind ont as loon too pupse tas to hame free fore sond of the the as ing toor the the and as tor foor toM agre the and of fore MjGonge. \n",
      "\n",
      "\"Noro bull yojus the dou the the Mas faly wolly of fore the and young the the rased and of the the Marry o\n",
      "14:42:18 End of epoch 51 , loss= 1.8757885694503784\n",
      " Harryy fared and ont ars off toh tare the the the saerd ont as tohe was toh ut shee sared off of forre the res ats at houd It as the act heard of for ber at sount inM agri the ars ajned sqoer ust acke fares and Molly, \"Is as tound and you gthe the the the rase saring the sore couss at loust and the\n",
      "14:42:34 End of epoch 52 , loss= 1.9095712900161743\n",
      " and and off you gthe the the the the reom and you got Mom at fore for Poonne sours it harse Mally ---- PNof usIt Mom Masre!\" \n",
      "\n",
      "\"YaM'ge Dally lused ing worut Fom und yaM lood an ther as there mese the the the reme ally and of thoug the reming to fore Vree mor mound and ous tine the the the the the r\n",
      "14:42:50 End of epoch 53 , loss= 1.8811562061309814\n",
      " Harryy four seme and ofun the the rome the sour tohe mas toh as fore the forre yConre yloo wuast the fill off you the war sof the daer tor tou star toh ter fary ofn oon tou the the the and of fore the the sVereme toon tous and of the froe sof tor merem off of fore Mfor and yoM and Gore tounrye qaun\n",
      "14:43:06 End of epoch 54 , loss= 1.8413310050964355\n",
      " suded thee sourpe jfere the the sared off as tohe was the and of forre tou sthe the sours,  Iand -of the dajres ass Baurs, ing toqeuut lily uVs arse jouls at as stot Her maind orfe fores tas corme fine the thee carse sary woand -- the the and as tound on the the fore toung he the the ras toonke wan\n",
      "14:43:22 End of epoch 55 , loss= 1.6617522239685059\n",
      " Harryy four seme the thee dares as tere mound int as at whee das to panred tou the as was too uppes at fore the the as wase the pead sound and tohe sted at Fourpe; yas it here forem Gonree sofrere same Groned to bere Vas tound and off orunt and you gat Mog the fared of tour bel.\" \n",
      "\n",
      "\"Youund, a siped\n",
      "14:43:39 End of epoch 56 , loss= 1.7338933944702148\n",
      " Harryy fore the was the the and one the pares at wase sto qouutd he the farry off of fore Mfaly fours, the Grored -jous sated at the as the farry off of fore Mfarry, Sone the rand oGfree the and yound and tou the and the the roomung the the round and young the the rased ing too qouut heas seme tor \n",
      "14:43:55 End of epoch 57 , loss= 1.6924850940704346\n",
      " Harryy fared jout sout sot has the the and as tow qoured as tou fing harty has the meand ont ereme sour sofre sourt and onte the you saed the and ing too fore the was the carrye fared Sone the the Marry and all young at looud the the meard of fore the and young the the rased and of the frougthe the\n",
      "14:44:11 End of epoch 58 , loss= 1.6011894941329956\n",
      " Harryy, fere sale whe the asn asd of fourd and tohe round at sourt Quirseed:  \n",
      "MSalully Fully ethe was the chereme sared fined an; the wase the yfor sofr ethe freed at Masr and ing too the sared fore the the saind off of tor Marr..\" \n",
      "\n",
      "\"ESone tor were saed Herery sof the the ethe sared fore soud the\n",
      "14:44:27 End of epoch 59 , loss= 1.579964280128479\n",
      " Harryy, bere saer was the cours and young he ting to at fore the the stor cous pear to and tor the fared Gofre the joust; Perevere soup Mas Gonre young ad looud the the mea dour soup peally tou the froud the the the the round and off orf at Masr and ing hout Goren goout hed and to upt as loout soug\n",
      "14:44:43 End of epoch 60 , loss= 1.6783552169799805\n",
      " Harryy fare the the stered at she at loougk int as the the farry off of the the Mrorf; Dounde Frey luly four Sone and orne saed the yan Voundd an dout Qiurseer Pfore sours ofur MoMg..\" OhM arry, Das Nulllee dount ars ofcerry enavered  Harrye sound and of the the and and and onte roughe the the the \n",
      "14:44:59 End of epoch 61 , loss= 1.6756600141525269\n",
      " Harryy fare the was the the and one the round and you the and as tow and thee the round and yout he at four sof for the the rasid fore Monre yas looud stal kon tou the fary to was the ster young at loout the soumde tar bout he fary the was tound the round and yout he and of the jtouss tere pouls at\n",
      "14:45:16 End of epoch 62 , loss= 1.6798220872879028\n",
      " Harryy fare the was the the pered at Mofre; fore Mrarmy, and and of pares jast of the the the saed Harry wase pares jas sowe the the and of fore Mrary and onte roud the Grone sour bout and you the fared Gofre yjous sare could and -ot wan the the the sared fore the there meas romes and ount as the t\n",
      "14:45:32 End of epoch 63 , loss= 1.633104920387268\n",
      " Harryy four saed the the wase sarid foor ufn at the was the and on tjoust and you the sared fared fore the the Sone the and as tow qout as fary tof the froud the yMonr and abree saed and Gonree jas toq aundig the the pall of fore the soud the pares taly fours the was the and -on tere sout hard Bout\n",
      "14:45:48 End of epoch 64 , loss= 1.6063921451568604\n",
      " Harryy -fere tal looud the and the was qouut ley the rased and yMong of fore the the Sone proomen sorust heard elte and yout sowe the the the and and young the the rased and young the the rased ing of for tou ghe Mrorf and of the yMorr.. \"You's jus tow and the and bole jturs ting the the and on at \n",
      "14:46:04 End of epoch 65 , loss= 1.6730772256851196\n",
      " Harryy, fere sate could lefe tor tou the the farry ing the the and of Morrfeo fury the door mes and oon ter at fourty he and of Pores sours, ing toquuing olf art hem as the pours jasn age the the the jas toou glollo was the the and of fered an tous the crousg the four toh fere the and of fore Mjas \n",
      "14:46:21 End of epoch 66 , loss= 1.681100606918335\n",
      " Harry, farry just as the the the and onte and orfe and to the the the tae parly off of forre the the dae Vas too for mere fours the carry off ofr the the the and onte croumsed an the the Ver of forre the CoMrerr and oMn ary, fally of Pored sout her as at Mas, and an the ywere saind on the ereme sar\n",
      "14:46:37 End of epoch 67 , loss= 1.643768310546875\n",
      " Harry, farry just and Gontery and ot hary the the fered an was the Ved qouutel ding to the the roumse courd an doout he farry off of the the wars tow and on tor her as the the mee Varry off of tor Marr. IE fome Ver ofre Groomuns jut wall. \n",
      "\n",
      "\"I the poer an doung the the rougthe the pould at was the \n",
      "14:46:54 End of epoch 68 , loss= 1.6257051229476929\n",
      " Harry, farry just and Bolted at Mas fore Pfore sjust himse coust Marred Goned on Pounted as Mosle Dufye loould and he the four saged the me tount ar young the the the fore soup and of for Magre, DMally ound Parry soup it Macluldly, Parry soud Mberr..\" \n",
      "\n",
      "THery was Marred Goned of Prores fours jqouuM\n",
      "14:47:10 End of epoch 69 , loss= 1.6279219388961792\n",
      " Harry, farry just walty the was the paerpe tound and the the Mrerry fours, Mally found and Gontery ajne sidn Pooffeer sor Morse could, Mally Fally,  It har's to wang the tar yout saed the to far was her and the seeper an tor the fore the was and to the pary tow and to the the the fore pours the for\n",
      "14:47:26 End of epoch 70 , loss= 1.537861943244934\n",
      " Harry, farry just was the farry offe the Buldye tou the do wat the the the parly off and at Marred afing the Proferes on Morre Dauss aclled aly ther and yout hard ing the the and as qouet ut hais sfere Dof unded an Morruly, fary the was the Cand on there saed was the the was and yout he farry off o\n",
      "14:47:42 End of epoch 71 , loss= 1.7250056266784668\n",
      " Harry, farry just walty the were tarse ting Ther and tow and to the the the fours the the roumse door Quutsere Verem jas tooud farry the fary the sowren to the dou the farry off and on Morre yound and and on the fours the the the fore soup and the the sared fary to wand the the to farry Dundely fou\n",
      "14:47:59 End of epoch 72 , loss= 1.630085825920105\n",
      " Harry, farry just walte tou the the parse to for fary fount he as ther as toon the tor Quurise fary found Ron and on tou the the farry off ofr the the the Soned an tour the and an Modle fours and yout and Ron onde tou the the was and the the pares as course for the fary found the the the and young \n",
      "14:48:15 End of epoch 73 , loss= 1.7129539251327515\n",
      " Harry, farry just walte the was the pars aftere to for Quurisding to the par tout har to fere to wans the to wars and yout and to the was the pary and of the fing to the poer some tou the for found and It he was the cours and young the the paret said the the the was and on; as there same the dount \n",
      "14:48:31 End of epoch 74 , loss= 1.7102257013320923\n",
      " Harry, farry just walte the for the farny of for tMer Gondo to wand the parry off and you the the saed an wars and it her afreed an the the farry of forre; was sModge tou jas to the the just an the poer sard: Thee saed Harry Fanly -- -an goold jout sot -o the \n",
      "fary -- Can and of the parres to nead \n",
      "14:48:47 End of epoch 75 , loss= 1.6938896179199219\n",
      " Harry, farry just at Madly fing to the the the rasned loougs the par tou the far yound ;t hars: the Modle foury Doung hary fours the forrem. \n",
      "\n",
      "\"I jouss Madle fous, Prery soud If and FMer!\" Bally Modre, \"I Cals, Fould ing to Founte, Harry, Ther and sore tou the frouds the fourty the fourty Modle fou\n",
      "14:49:03 End of epoch 76 , loss= 1.6861785650253296\n",
      " Harry, farry just at Momed and on at and Boutghe the perasd to the ping to was the pout as thee dor, \"- \n",
      "\n",
      "\"Wher and It he was paly the peres as wasinge the the the farly ing ow and to the parly of for the fore tou the sopup parse fore find an Marding,\" Harry, as waind Fing ot at harse parse fing to\n",
      "14:49:19 End of epoch 77 , loss= 1.7851978540420532\n",
      " Harry, far; yjus and the was the CGone round and yout hais som Qoureed an Verrey the Goner offe to the the L-angy of on the was the fary to saed ar of fere tow and the to wand to the paret was it haind and the afrey --- fou the far the farly ond of --- foung the the the pares and of the paress tow \n",
      "14:49:36 End of epoch 78 , loss= 1.5221432447433472\n",
      " Harry, farry just at Madly and on and at Magroud fing the the to was her and of the pares taly fing ont ande the pout an the pere some tor the found and the the and to the perass ting the wast at wall youst and the the the the fary off of froouds the MHerray, \"Was ad and Pores fourse M-Mgor, and Po\n",
      "14:49:53 End of epoch 79 , loss= 1.7351856231689453\n",
      " Harry, farry just at Madly and and ar and the ther and young the the the farry off ofr of for MMorr, ED Fald yous and Grery off Promes,\" MI jas Mally of Promes!\"\" MRer's and and Poer yous iMser's as ande MParry, L- any onde jas sow and the the Verem and young the pire found sing to the the tou the \n",
      "14:50:09 End of epoch 80 , loss= 1.5006792545318604\n",
      " Harry, -be and an was the paund and the the remesd ar off and Pofreed Ron, Momre fours, Magridl and Non the paret was and the pares saind on the res as was qouter and yout he farry fand of the firned the fours it hard youlg. \n",
      "\n",
      "\"I to fours an the pours inde as off yount and : Hut wat hard sowen the \n",
      "14:50:26 End of epoch 81 , loss= 1.6468944549560547\n",
      " Harry, farry just at Madn Gonded an jast an was querey ing of the found it Magror and of -the the the calke was and was qouteud an Mgorde four Nin Goroud for; Duscally, youn gout her as tou the fary for tou the fary to fere toung the the the the fared an was her and tow and to the the the fary und \n",
      "14:50:42 End of epoch 82 , loss= 1.7162036895751953\n",
      " Harry, farry just at Magloud and Gonrey fours, the found GAn gout he fary the wass the pere ass and to the for fours the che Vares on and Gore tount and yout sol was the paret was and to the the fary some the res qoutere saind and young the the carse for the was qoutere saing to the fourt Mag of Po\n",
      "14:50:58 End of epoch 83 , loss= 1.7627146244049072\n",
      " Harry, farry just and Bolted of the parte the dor found and the the parces as the roungd to the the firg as the for for fore coust he fing of the the Marred. I was at wally to the sad Pore tous it Qareersill, has pire fous and the --- balke found and yout -- Mjas soand it Pofeers of It Mcolly found\n",
      "14:51:14 End of epoch 84 , loss= 1.616836428642273\n",
      " Harry, farry just and Gontery of forre the fir ming to was the the saer. \n",
      "\n",
      "\"I found and the the to fere to fere to ther saed Harry fand on and the the the just and Gonogres tar the the firg tound and; you the was and the the sorme for envery of -- -- It ham and to fare MGand young the the the parli\n",
      "14:51:30 End of epoch 85 , loss= 1.5945017337799072\n",
      " Harry, farry just and Gontery and ot har Mgorfe Dan bulled ary of the pareld t- and young the the the tar for fore Mand and and ar and young the the the tar poen to for the fary fout the Greon and and ount and the tead an the the romeed to the the paresd at Magroud Dar and Pores Futlyo ufred and Ho\n",
      "14:51:46 End of epoch 86 , loss= 1.7280516624450684\n",
      " Harry, farry just as the the was tar ing to was the the was the wary tow and to the the fours and the the wars and young the the the was faridn to the parse wass the peared -- fay the fout the Grey off ar the for found and the the juste pars as the parisn and the to paing to was the the for Marging\n",
      "14:52:02 End of epoch 87 , loss= 1.688260555267334\n",
      " Harry, farry just as theed and to fere to fere tou the fary to farne the the was tar off on tou the freed t- Harry fing ot Maglold wat and at looke sing to the was the the parly fount and on the farry sout he farje swall whas et of -t hat was at her young the fourt and the good to the was and to th\n",
      "14:52:19 End of epoch 88 , loss= 1.6909310817718506\n",
      " Ron, In as of Quurlye Thee crousge door the far forme the the fore to fary the was tow and the poer Sone paring to the was and qouter ins as the pares at Harry fourg, the was and to the was as the cours find ar offe to the the Loomus and of qouteing to the poe was sared on the qeurey and ing to fou\n",
      "14:52:35 End of epoch 89 , loss= 1.6610342264175415\n",
      " Harry, fary the was and to the the fing to wary foung the the the to was as and the was and the wared -- young the the the wars and yout and to the fere to fary the for toung the the to was the fours the for far forne sor Moglolow and wa; yous ing to the for fout her and an doolke wasj to the for f\n",
      "14:52:51 End of epoch 90 , loss= 1.8023242950439453\n",
      " Harry, fary, just as Magly and and of the firget hard fore Marde. Pures was of the GRonge. \"I Modr's and an goollo ke --- of upp, the the fere to fary the was and to the the pary fore coumde, an dout he sary the tarke fing to the was qouter ing of the the pary sof of the cours pary found and to the\n",
      "14:53:07 End of epoch 91 , loss= 1.7435094118118286\n",
      " Ron mound and yout haid Nor paut loout sto the the foury find of the for the fary to fere to for the was and the the romeed an young the the rame sours fing to the the was and the pares it Harry; fours and to the parke sidn at Macly foung at Marde and and ing to the the Darrey just and of the pared\n",
      "14:53:24 End of epoch 92 , loss= 1.7095924615859985\n",
      " Harry, fary the was and to the the Darrey sours ing off off the the the freod an wars and young the the roup and to the the the rasy of Snoten there casse to feer Mars af;o the was as tow and the pared jass ting of there t- an was as to pere fout Malfy and an the the fing ar ofred the was and the p\n",
      "14:53:40 End of epoch 93 , loss= 1.724847674369812\n",
      " Harry, farry just at MGondy an waly the wand the gout Nor young the the the was and to the the was as the fours finde the was; Norse four Efing to the the rasted an was at lighe the was and the poer saed an the qouute liske waly was quiter as and the was and to the perasing to was the the saer, fir\n",
      "14:53:56 End of epoch 94 , loss= 1.6106646060943604\n",
      " Harry, and her anded and the the tou the for fours and the pares as and the cared the and young the the rasd and to the ree moung the the tou the fary of for fore Mand Gondery of Poret suag the DMorred Tall Herrye was sorme wad and the the the for found and the the the was as too the fury fout Mag \n",
      "14:54:12 End of epoch 95 , loss= 1.6416279077529907\n",
      " Harry, fare, jass id ab ountd an the the pary to the pares was; Thee der an Magly of the the carse paring to for the the the taring to the pary to the the saed Harry feer and to thee MRard. The Parrese sores jusse doout the was qaerey quuse ding of fire thary saing to wand the perasing to for the t\n",
      "14:54:28 End of epoch 96 , loss= 1.5924293994903564\n",
      " Harry, fary, just hard fout Mard Gandey Harry quallly the goudt and the gout the saer an wars to the the ther and ar and the ther Sone pares jast to the saed Harry foulld at was the the fary found the the the was and the gooturs te; Sone the was and an wary the sere the sorem if afret -Ron and the \n",
      "14:54:44 End of epoch 97 , loss= 1.7764300107955933\n",
      " Harry, fary the was and to the saed an to fere the there sad an was ese Vall wouds fing to the the rome some the roung the the the fourry Modly, and and an goutqeurey the maridn joust he fing the the mound; It of the per of for Gonog his the pary foof; Whe -- It was and of Pores fours, coust Mall y\n",
      "14:54:59 End of epoch 98 , loss= 1.566001057624817\n",
      " Harry, fary the was and to there was and the coust and yout he firde the the roungd at of the the Marred an on and as quereid and to fing the the for for the poere sasing to was the the the was and on thee Verem and young to the the Lone saed of the for the fary found and the theed -- Hagre qaully \n",
      "14:55:16 End of epoch 99 , loss= 1.5087370872497559\n",
      " Harry fing on the the was tary to the the tou the for for for fore Mas Mad foom and Gory Fuldeldy -- an dor an ther and an the pout an the pere saind an the pounted an yount as the the was qouteing to the the was Margould -goout the the the the Darled yous the romuste dor was and young the the the \n",
      "14:55:32 End of epoch 100 , loss= 1.620995044708252\n",
      " Harry, fary the was and to the the Darred young the was erex to chem anrey on and ter at harse; Sone Preverye sale wis the Magrre Das Sande Darlye sould and joust as Magly and and on eary the the fourt ind an wary sore coust jast had for for the saer and to qoutel yas the the maed sing of It he was\n"
     ]
    }
   ],
   "source": [
    "# ======================= Training ======================= #\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Running on\", device)\n",
    "\n",
    "config = Config()\n",
    "training_dataset = CharDataset('HP_book_1.txt', 32)\n",
    "print(\"There are\", len(training_dataset), \"datapoints and\", len(id_to_char), \"unique characters in the dataset\") \n",
    "training_loader = DataLoader(training_dataset, batch_size=config.batch_size)\n",
    "\n",
    "charlm = CharLM(config, len(id_to_char)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "charlm_optimizer = optim.Adam(charlm.parameters(), lr=config.learning_rate)\n",
    "\n",
    "charlm.train()\n",
    "print(datetime.now().strftime(\"%X\"), \"Training starts\")\n",
    "for epoch in range(config.no_of_epochs):\n",
    "    iteration = 0\n",
    "    for input_tensor, label in training_loader:\n",
    "        input_tensor, label = input_tensor.to(device), label.to(device)\n",
    "        charlm_optimizer.zero_grad()\n",
    "        logits = charlm(input_tensor).to(device)\n",
    "        loss = criterion(logits.squeeze(1), label)\n",
    "        loss.backward()\n",
    "        charlm_optimizer.step()\n",
    "        iteration += 1\n",
    "\n",
    "    print(datetime.now().strftime(\"%X\"), \"End of epoch\", epoch+1, \", loss=\", loss.detach().item())\n",
    "    charlm.eval()\n",
    "    print()\n",
    "    # Generate 50 characters starting from the input text\n",
    "    try:\n",
    "        char_list = list(\"he took out his wand and\"[-MAXLEN:])\n",
    "        for i in range(300):\n",
    "            input_tensor = torch.tensor([char_to_id[c] for c in char_list] + [char_to_id[PADDING_SYMBOL]]*(MAXLEN-len(char_list))).unsqueeze(0).to(device)\n",
    "            logits = charlm(input_tensor).squeeze().to(device)\n",
    "            _, new_character_tensor = logits.topk(1)\n",
    "            new_character = id_to_char[new_character_tensor.detach().item()]\n",
    "            print(new_character, end='')\n",
    "            if len(char_list) == MAXLEN:\n",
    "                char_list.pop(0)\n",
    "            char_list.append(new_character)\n",
    "        print()\n",
    "    except KeyError:\n",
    "        continue\n",
    "    charlm.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac9b627-90e7-440e-8dae-920030e9b99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Harry said\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gryffindor was Mard af Poastou Vre couss one Ther\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Voldemort and Harry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and the Mrerrey wall witghe them ind an warde the\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Non, Racis qoouking the qaully us and of -coan; t\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Ron\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the said Ron Quirrell on and ared aqeutiund -- am\n"
     ]
    }
   ],
   "source": [
    "# ==================== User interaction ==================== #\n",
    "\n",
    "while True:\n",
    "    text = input(\"> \").strip()\n",
    "    if text == \"\":\n",
    "        continue\n",
    "    char_list = list(text[-MAXLEN:])\n",
    "    # Generate 50 characters starting from the input text\n",
    "    try:\n",
    "        for i in range(50):\n",
    "            input_tensor = torch.tensor([char_to_id[c] for c in char_list] + [char_to_id[PADDING_SYMBOL]]*(MAXLEN-len(char_list))).unsqueeze(0).to(device)\n",
    "            logits = charlm(input_tensor).squeeze().to(device)\n",
    "            _, new_character_tensor = logits.topk(1)\n",
    "            new_character = id_to_char[new_character_tensor.detach().item()]\n",
    "            print(new_character, end='')\n",
    "            if len(char_list) == MAXLEN:\n",
    "                char_list.pop(0)\n",
    "            char_list.append(new_character)\n",
    "        print()\n",
    "    except KeyError:\n",
    "        continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
