{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e9fd866532a136",
   "metadata": {},
   "source": [
    "# Word prediction - neural network approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71cb74a1-cf32-4642-a53c-42090dafe1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import json\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81a15723-25c5-4282-981c-6fee9da4c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import START_SYMBOL, PADDING_SYMBOL, UNK_SYMBOL, NUM_PREDICTIONS, EXTRINSIC_EVAL_SIZE\n",
    "from prepare import tokenize_sentences, train_val_test_split, buildWordIdMappings\n",
    "from evaluate import evaluate_extrinsic\n",
    "from gui import get_gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774efab5-f7e6-45de-9085-4b12938c9c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12180c34e88e2583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: NVIDIA H100 80GB HBM3 MIG 1g.10gb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_SIZE = 25\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "USE_GRU = True\n",
    "TUNE_EMBEDDINGS = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current device: {}\".format(torch.cuda.get_device_name(0)))\n",
    "else:\n",
    "    print('Running on CPU')\n",
    "print()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "575d260c-20fb-47d1-ab4f-c1bf1b7e3af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing input corpus...\n",
      "Tokenization ready.\n",
      "Train dataset size: 51035\n",
      "Validation dataset size: 17012\n",
      "Test dataset size: 17012\n"
     ]
    }
   ],
   "source": [
    "sentences = tokenize_sentences(\"data/HP_all.txt\", [START_SYMBOL])\n",
    "train_sentences, validation_sentences, test_sentences = train_val_test_split(sentences)\n",
    "w2i, i2w = buildWordIdMappings(train_sentences)\n",
    "train_vocab = len(i2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb05d11d8fb90f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordDataset(Dataset):\n",
    "    def __init__(self, sentences):\n",
    "        self.previous_words = []\n",
    "        self.next_word = []\n",
    "        for s in sentences:\n",
    "            for (i, word) in enumerate(s):\n",
    "                if i > 0:\n",
    "                    self.previous_words.append([w2i.get(s[j], w2i[UNK_SYMBOL]) for j in range(i)])\n",
    "                    self.next_word.append(w2i.get(word, w2i[UNK_SYMBOL]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.previous_words)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.previous_words[idx], self.next_word[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b8fa05d4e90802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function below will take care of the case of sequences of unequal lengths\n",
    "def pad_sequence(batch, pad=w2i[PADDING_SYMBOL]):\n",
    "    previous_words, next_word = zip(*batch)\n",
    "    max_len = max(map(len, previous_words))\n",
    "    padded_previous_words = [[b[i] if i < len(b) else pad for i in range(max_len)] for b in previous_words]\n",
    "    return padded_previous_words, next_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a691c562-fcdc-4e3c-b1b4-a11a0c923203",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = WordDataset(train_sentences)\n",
    "validation_dataset = WordDataset(validation_sentences)\n",
    "test_dataset = WordDataset(test_sentences)\n",
    "\n",
    "train_loader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_sequence)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, collate_fn=pad_sequence)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=pad_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings...\n",
      "Word vectors loaded.\n"
     ]
    }
   ],
   "source": [
    "def load_glove_embeddings(embedding_file):\n",
    "    \"\"\"\n",
    "    Reads pre-made embeddings from a file\n",
    "    \"\"\"\n",
    "    N = len(w2i)\n",
    "    embeddings = [0] * N\n",
    "    with codecs.open(embedding_file, 'r', 'utf-8') as f:\n",
    "        for line in f:\n",
    "            data = line.split()\n",
    "            word = data[0].lower()\n",
    "            if word not in w2i:\n",
    "                w2i[word] = N\n",
    "                i2w.append(word)\n",
    "                N += 1\n",
    "                embeddings.append(0)\n",
    "            vec = [float(x) for x in data[1:]]\n",
    "            D = len(vec)\n",
    "            embeddings[w2i[word]] = vec\n",
    "    # Add a '0' embedding for the padding symbol\n",
    "    embeddings[0] = [0] * D\n",
    "    # Check if there are words that did not have a ready-made Glove embedding\n",
    "    # For these words, add a random vector\n",
    "    for word in w2i:\n",
    "        index = w2i[word]\n",
    "        if embeddings[index] == 0:\n",
    "            embeddings[index] = (np.random.random(D) - 0.5).tolist()\n",
    "    return D, embeddings\n",
    "\n",
    "\n",
    "print(\"Loading GloVe embeddings...\")\n",
    "embedding_size, embeddings = load_glove_embeddings('data/glove.6B.50d.txt')\n",
    "print(\"Word vectors loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "496df054725d7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings=None, embedding_size=16, hidden_size=25, device='cpu', use_gru=True, tune_embeddings=False):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        if embeddings is not None:\n",
    "            self.embedding.weight = nn.Parameter(torch.tensor(embeddings, dtype=torch.float), requires_grad=tune_embeddings)\n",
    "        if use_gru:\n",
    "            self.rnn = nn.GRU(embedding_size, hidden_size, batch_first=True)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(embedding_size, hidden_size, batch_first=True)\n",
    "        self.output = nn.Linear(hidden_size, vocab_size)\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        hidden, output = self.rnn(self.embedding(x), hidden)\n",
    "        output = self.output(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75fc8674c09b1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader, model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print('Evaluating RNN model...')\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            x = torch.tensor(x).to(device)\n",
    "            y = torch.tensor(y).to(device)\n",
    "            y_pred, _ = model(x)\n",
    "            y_pred = y_pred.squeeze()\n",
    "            _, predicted = torch.max(y_pred.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "    print('Accuracy: {:.2f}%'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51c7a47fcfe537e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(len(w2i), embeddings, embedding_size, HIDDEN_SIZE, device, USE_GRU, TUNE_EMBEDDINGS)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a24f177c72dbd9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10\n",
      "Evaluating RNN model...\n",
      "Accuracy: 16.45%\n",
      "Epoch: 2/10\n",
      "Evaluating RNN model...\n",
      "Accuracy: 18.98%\n",
      "Epoch: 4/10\n",
      "Evaluating RNN model...\n",
      "Accuracy: 18.90%\n",
      "Epoch: 5/10\n",
      "Evaluating RNN model...\n",
      "Accuracy: 19.35%\n",
      "Epoch: 6/10\n",
      "Evaluating RNN model...\n",
      "Accuracy: 19.76%\n",
      "Epoch: 7/10\n",
      "Evaluating RNN model...\n",
      "Accuracy: 19.72%\n",
      "Epoch: 8/10\n",
      "Evaluating RNN model...\n",
      "Accuracy: 19.71%\n",
      "Epoch: 9/10\n",
      "Evaluating RNN model...\n",
      "Accuracy: 19.73%\n",
      "Epoch: 10/10\n",
      "Evaluating RNN model...\n",
      "Accuracy: 20.24%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print('Epoch: {}/{}'.format(epoch + 1, NUM_EPOCHS))\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        x = torch.tensor(x).to(device)\n",
    "        y = torch.tensor(y).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred, _ = model(x)\n",
    "        loss = criterion(y_pred.squeeze(), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    evaluate(validation_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20dd52f6-eb2d-45a6-a2af-211dfae774fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    dt = str(datetime.now()).replace(' ','_').replace(':','_').replace('.','_')\n",
    "    newdir = 'nn/model_' + dt\n",
    "    os.mkdir(newdir)\n",
    "    torch.save(model.state_dict(), os.path.join(newdir, 'model'))\n",
    "    with open(os.path.join(newdir, 'w2i'), 'wb') as f:\n",
    "        pickle.dump(w2i, f)\n",
    "        f.close()\n",
    "    with open(os.path.join(newdir, 'i2w'), 'wb') as f:\n",
    "        pickle.dump(i2w, f)\n",
    "        f.close()\n",
    "\n",
    "    settings = {\n",
    "        'epochs': NUM_EPOCHS,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'hidden_size': HIDDEN_SIZE,\n",
    "        'embedding_size': embedding_size,\n",
    "        'use_gru': USE_GRU,\n",
    "        'tune_embeddings': TUNE_EMBEDDINGS\n",
    "    }\n",
    "    with open(os.path.join(newdir, 'settings.json'), 'w') as f:\n",
    "        json.dump(settings, f)\n",
    "\n",
    "\n",
    "save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349107a5-9019-4946-ade8-872646a6e476",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf367c10-f2b2-4dbb-8899-b2e2c491006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "def load_model(model_dir):    \n",
    "    f = open(model_dir + 'settings.json')\n",
    "    settings = json.load(f)    \n",
    "    m = RNNModel(len(w2i), None, settings['embedding_size'], settings['hidden_size'], device, settings['use_gru'], settings['tune_embeddings'])\n",
    "    f.close()\n",
    "    m.load_state_dict(torch.load(model_dir + 'model'))\n",
    "    m.eval()\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f60d6f5-428d-49ba-811f-9f7d0889b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('nn/model_2024-05-21_21_14_32_520995/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfedb9d8-f8c6-4faa-84d1-7ca9319d9073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RNN model...\n",
      "Accuracy: 20.36%\n"
     ]
    }
   ],
   "source": [
    "evaluate(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd0a133f-3b99-45c1-9df7-677e0b936b7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class WordPredictorModel:\n",
    "    def __init__(self, model, predict_from_all_words=True):\n",
    "        self.model = model\n",
    "        self.predict_from_all_words = predict_from_all_words\n",
    "        self.last_previous_words = None\n",
    "        self.y_pred = None\n",
    "        self.possible_words = None\n",
    "    \n",
    "    def predict(self, previous_words, typed_characters, k):\n",
    "        if self.last_previous_words == previous_words:\n",
    "            self.possible_words = [i for i in self.possible_words if i2w[i].startswith(typed_characters)]\n",
    "        else:\n",
    "            x = [w2i.get(w, w2i[UNK_SYMBOL]) for w in previous_words]\n",
    "            x = torch.tensor(x).to(device)\n",
    "            y_pred, _ = self.model(x)\n",
    "            self.y_pred = y_pred.squeeze()\n",
    "            if self.predict_from_all_words:\n",
    "                self.possible_words = [i for (i, w) in enumerate(i2w) if w.startswith(typed_characters)]\n",
    "            else:\n",
    "                self.possible_words = [i for i in range(train_vocab) if i2w[i].startswith(typed_characters)]\n",
    "            self.last_previous_words = previous_words\n",
    "        possible_pred = self.y_pred[self.possible_words]\n",
    "        _, best = possible_pred.topk(min(k, len(possible_pred)))\n",
    "        best = [i2w[self.possible_words[b]] for b in best]\n",
    "        return best, len(self.possible_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "576ad48f-d9d9-40b4-944a-ca1e9facc3df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "word_predictor = WordPredictorModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e46110-9b4a-4ba2-8524-120bed51a493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    evaluate_extrinsic(test_sentences[:EXTRINSIC_EVAL_SIZE], word_predictor, NUM_PREDICTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "809f95d2-f69d-45c7-9fd2-4839cdb43521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://5a843cd8b6633298cc.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5a843cd8b6633298cc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    get_gui(word_predictor, 'recurrent neural network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47ae37b8-05fe-45a9-8657-6f12e5ad4a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing input corpus...\n",
      "Tokenization ready.\n",
      "Train dataset size: 20203\n",
      "Validation dataset size: 6734\n",
      "Test dataset size: 6735\n",
      "k=4 suggestion(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keystrokes evaluation: 100%|██████████| 1000/1000 [45:00<00:00,  2.70s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Keystrokes: 67488\n",
      " All characters: 112965\n",
      " Keystroke savings: 40.26%\n",
      " Average number of possible words when correctly guessed: 55884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "guardian_test = tokenize_sentences(\"data/guardian_test.txt\", [START_SYMBOL])\n",
    "_, _, guardian_test = train_val_test_split(guardian_test)\n",
    "with torch.no_grad():\n",
    "    evaluate_extrinsic(guardian_test[:EXTRINSIC_EVAL_SIZE], word_predictor, NUM_PREDICTIONS[-1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
